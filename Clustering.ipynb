{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importar as Bibliotecas Necessárias\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.stats import entropy\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import completeness_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./dataset/dados_normalizados.csv\")\n",
    "\n",
    "X = data.iloc[:, :-1].values  # Excluindo a coluna 'Class' ou a última coluna\n",
    "y_true = data['Class'].values\n",
    "\n",
    "# 3. Normalizar os Dados\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X) \n",
    "# print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_coesao(X, labels):\n",
    "    coesao_total = 0\n",
    "    for label in np.unique(labels):\n",
    "        if label == -1:  # Ignorar ruído, se houver\n",
    "            continue\n",
    "        cluster_points = X[labels == label]\n",
    "        distancias = pdist(cluster_points)  # Calcula as distâncias entre todos os pares\n",
    "        coesao_total += np.sum(distancias)\n",
    "    return coesao_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = -1\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "\n",
    "for n_clusters in (2,3,4,5,6,7,8):\n",
    "    for max_iter in (100,200,300,400,500):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iter, random_state=0)\n",
    "        kmeans.fit(X)\n",
    "\n",
    "        score = kmeans.inertia_\n",
    "\n",
    "        if(score > best):\n",
    "            best_j = max_iter\n",
    "            best_i = n_clusters\n",
    "\n",
    "kmeans = KMeans(n_clusters=best_i, max_iter=best_j, random_state=0)\n",
    "labels_pred_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "print(f'Best n_clusters: {best_i}, Best max_iter: {best_j}')\n",
    "\n",
    "print(\"\\nCoesão: \", math.sqrt(kmeans.inertia_)/kmeans.n_clusters)\n",
    "\n",
    "print(\"\\nCoeficiente de silhueta médio: \", kmeans.inertia_)\n",
    "\n",
    "print(\"\\nHomogeneidade : \",metrics.homogeneity_score(y_true,kmeans.labels_))\n",
    "\n",
    "print(\"\\nSeparação: \", pairwise_distances(kmeans.cluster_centers_).mean())\n",
    "\n",
    "print(\"\\nRand Score K-means: \",metrics.rand_score(y_true, kmeans.labels_))\n",
    "\n",
    "print(\"\\nCompletude: \", completeness_score(y_true, kmeans.labels_))\n",
    "\n",
    "print(\"\\nEntropia: \", entropy(np.bincount(kmeans.labels_)/len(kmeans.labels_)))\n",
    "\n",
    "# – Coesao˜ok\n",
    "# – Separac¸ao˜ ok\n",
    "# – Coeficiente de Silhueta Medio ´ok\n",
    "# – Homogeneidade ok\n",
    "# – ´Indice Randomico okˆ\n",
    "# – Completude ok\n",
    "# – Entropia ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar os resultados\n",
    "plt.figure(figsize=(16, 6))    \n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_true, cmap='plasma', marker='o', edgecolor='k', s=100)\n",
    "plt.title('Rótulos Reais', fontsize=16)\n",
    "plt.xlabel('Componente Principal 1', fontsize=14)\n",
    "plt.ylabel('Componente Principal 2', fontsize=14)\n",
    "plt.colorbar(scatter, label='Clusters')\n",
    "\n",
    "# Segundo Subplot: Rótulos Preditivos de Clusters\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels_pred_kmeans, cmap='plasma', marker='o', edgecolor='k', s=100)\n",
    "plt.title('Rótulos Preditivos de Clusters (K-Means)', fontsize=16)\n",
    "plt.xlabel('Componente Principal 1', fontsize=14)\n",
    "plt.ylabel('Componente Principal 2', fontsize=14)\n",
    "plt.colorbar(scatter, label='Clusters')\n",
    "plt.grid(True)\n",
    "\n",
    "# Salvar a Figura\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = -1\n",
    "\n",
    "for eps in (0.1, 0.2, 0.3, 0.4, 0.5):\n",
    "    for min_s in (5, 10, 15, 20, 50):\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_s)\n",
    "        dbscan.fit(X)\n",
    "\n",
    "        if len(set(dbscan.labels_)) > 1:  # Verifica se há mais de 1 cluster\n",
    "            score = silhouette_score(X, dbscan.labels_)\n",
    "            \n",
    "            # Verificar se o score atual é melhor que o melhor score já encontrado\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_eps = eps\n",
    "                best_min_samples = min_s\n",
    "                \n",
    "\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "labels_pred_dbsacn = dbscan.fit_predict(X)\n",
    "\n",
    "dist_matrix = pairwise_distances(X)\n",
    "\n",
    "total_cohesion = 0\n",
    "total_separation = 0\n",
    "num_clusters = len(set(labels_pred_dbsacn)) - (1 if -1 in labels_pred_dbsacn else 0)\n",
    "\n",
    "for cluster_label in set(labels_pred_dbsacn):\n",
    "    if cluster_label == -1:\n",
    "        continue  # Ignora pontos de ruído\n",
    "    \n",
    "    # Índices dos pontos do cluster atual\n",
    "    indices_current = np.where(labels_pred_dbsacn == cluster_label)[0]\n",
    "    \n",
    "    # Cálculo da coesão\n",
    "    if len(indices_current) <= 1:\n",
    "        continue  # Evita divisão por zero\n",
    "    sum_dist_cohesion = np.sum(dist_matrix[np.ix_(indices_current, indices_current)])\n",
    "    num_pairs_cohesion = len(indices_current) * (len(indices_current) - 1)\n",
    "    cohesion = sum_dist_cohesion / num_pairs_cohesion\n",
    "    total_cohesion += cohesion\n",
    "    \n",
    "    # Cálculo da separação mínima com outros clusters\n",
    "    min_separation = np.inf\n",
    "    for other_cluster_label in set(labels_pred_dbsacn):\n",
    "        if other_cluster_label == cluster_label or other_cluster_label == -1:\n",
    "            continue\n",
    "        indices_other = np.where(labels_pred_dbsacn == other_cluster_label)[0]\n",
    "        separation = np.min(dist_matrix[np.ix_(indices_current, indices_other)])\n",
    "        min_separation = min(min_separation, separation)\n",
    "    \n",
    "    total_separation += min_separation\n",
    "\n",
    "\n",
    "\n",
    "print(f'Best EPS: {best_eps}, Best Min Samples: {best_min_samples}')\n",
    "\n",
    "if num_clusters > 0:\n",
    "    average_cohesion = total_cohesion / num_clusters\n",
    "    average_separation = total_separation / num_clusters\n",
    "    print(f\"\\nCoesão Média dos Clusters: {average_cohesion:.4f}\")\n",
    "    print(f\"\\nSeparação Média dos Clusters: {average_separation:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNenhum cluster válido encontrado.\")\n",
    "\n",
    "#print(\"\\nCoeficiente de Silhueta: \", metrics.silhouette_score(X_pca,dbscan.labels_))\n",
    "\n",
    "print(\"\\nHomogeneidade : \",metrics.homogeneity_score(y_true,dbscan.labels_))\n",
    "\n",
    "print(\"\\nRand Score: \",metrics.rand_score(y_true, dbscan.labels_))\n",
    "\n",
    "print(\"\\nCompletude: \", completeness_score(y_true, dbscan.labels_))\n",
    "\n",
    "print(\"\\nEntropia: \", entropy(np.bincount(dbscan.labels_[dbscan.labels_ != -1])/len(dbscan.labels_)))\n",
    "\n",
    "# – Coesao˜ok\n",
    "# – Separac¸ao˜\n",
    "# – Coeficiente de Silhueta Medio ´ok\n",
    "# – Homogeneidade ok\n",
    "# – ´Indice Randomico okˆ\n",
    "# – Completude ok\n",
    "# – Entropia ok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))    \n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_true, cmap='plasma', marker='o', edgecolor='k', s=100)\n",
    "plt.title('Rótulos Reais', fontsize=16)\n",
    "plt.xlabel('Componente Principal 1', fontsize=14)\n",
    "plt.ylabel('Componente Principal 2', fontsize=14)\n",
    "plt.colorbar(scatter, label='Clusters')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels_pred_dbsacn, cmap='plasma', marker='o', edgecolor='k', s=100)\n",
    "plt.title('Resultados do DBSCAN', fontsize=16)\n",
    "plt.xlabel('Componente Principal 1', fontsize=14)\n",
    "plt.ylabel('Componente Principal 2', fontsize=14)\n",
    "plt.colorbar(scatter, label='Clusters')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = -1\n",
    "\n",
    "for n_clusters in (2,3,4,5,6,7,8):\n",
    "    for linkage in ('ward', 'complete', 'average', 'single'):\n",
    "        agnes = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
    "        agnes.fit(X)\n",
    "\n",
    "        if len(set(agnes.labels_)) > 1:\n",
    "            score = silhouette_score(X, agnes.labels_)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_linkage = linkage\n",
    "                best_ncluster = n_clusters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agnes = AgglomerativeClustering(n_clusters=best_ncluster, linkage=best_linkage)\n",
    "labels_pred_agnes = agnes.fit_predict(X)\n",
    "\n",
    "dist_matrix = pairwise_distances(X)\n",
    "\n",
    "total_cohesion = 0\n",
    "num_clusters = len(set(labels_pred_agnes))\n",
    "\n",
    "for cluster_label in set(labels_pred_agnes):\n",
    "\n",
    "    indices_current = np.where(labels_pred_agnes == cluster_label)[0]\n",
    "    \n",
    "\n",
    "    if len(indices_current) <= 1:\n",
    "        continue  \n",
    "    sum_dist_cohesion = np.sum(dist_matrix[np.ix_(indices_current, indices_current)])\n",
    "    num_pairs_cohesion = len(indices_current) * (len(indices_current) - 1)\n",
    "    cohesion = sum_dist_cohesion / num_pairs_cohesion\n",
    "    total_cohesion += cohesion\n",
    "    \n",
    "\n",
    "    min_separation = np.inf\n",
    "    for other_cluster_label in set(labels_pred_agnes):\n",
    "        if other_cluster_label == cluster_label:\n",
    "            continue\n",
    "        indices_other = np.where(labels_pred_agnes == other_cluster_label)[0]\n",
    "        separation = np.min(dist_matrix[np.ix_(indices_current, indices_other)])\n",
    "        min_separation = min(min_separation, separation)\n",
    "    \n",
    "    total_separation += min_separation\n",
    "\n",
    "print(f'Best linkage: {best_linkage}, Best n_clusters: {best_ncluster}')\n",
    "\n",
    "if num_clusters > 0:\n",
    "    average_cohesion = total_cohesion / num_clusters\n",
    "    average_separation = total_separation / num_clusters\n",
    "    print(f\"\\nCoesão Média dos Clusters: {average_cohesion:.4f}\")\n",
    "    print(f\"\\nSeparação Média dos Clusters: {average_separation:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNenhum cluster encontrado.\")\n",
    "\n",
    "print(\"\\nCoeficiente de Silhueta médio: \", best_score)\n",
    "\n",
    "print(\"\\nHomogeneidade : \",metrics.homogeneity_score(y_true,agnes.labels_))\n",
    "\n",
    "print(\"\\nRand Score: \",metrics.rand_score(y_true, agnes.labels_))\n",
    "\n",
    "print(\"\\nCompletude: \", completeness_score(y_true, agnes.labels_))\n",
    "\n",
    "print(\"\\nEntropia: \", entropy(np.bincount(agnes.labels_)/len(agnes.labels_)))\n",
    "\n",
    "# – Coesao˜ok\n",
    "# – Separac¸ao˜\n",
    "# – Coeficiente de Silhueta Medio ´ok\n",
    "# – Homogeneidade ok\n",
    "# – ´Indice Randomico okˆ\n",
    "# – Completude ok\n",
    "# – Entropia ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))    \n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_true, cmap='plasma', marker='o', edgecolor='k', s=100)\n",
    "plt.title('Rótulos Reais', fontsize=16)\n",
    "plt.xlabel('Componente Principal 1', fontsize=14)\n",
    "plt.ylabel('Componente Principal 2', fontsize=14)\n",
    "plt.colorbar(scatter, label='Clusters')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels_pred_agnes, cmap='plasma', marker='o', edgecolor='k', s=100)\n",
    "plt.title('Resultados do AGNES', fontsize=16)\n",
    "plt.xlabel('Componente Principal 1', fontsize=14)\n",
    "plt.ylabel('Componente Principal 2', fontsize=14)\n",
    "plt.colorbar(scatter, label='Clusters')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
